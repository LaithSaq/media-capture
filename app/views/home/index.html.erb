
<% content_for(:head) do %>
  <script src="https://webrtc.github.io/adapter/adapter-latest.js"></script>
  <script >
    $(function() {
      const audio = document.querySelector('audio');
      const constraints = window.constraints = {
        audio: true,
        video: false
      };

      async function handleSuccess(stream) {
        const audioTrack = stream.getAudioTracks()[0];
        // console.log('Got stream with constraints:', constraints);
        // console.log('Using audio device: ' + audioTrack.label);
        stream.oninactive = function() {
          console.log('Stream ended');
        };
        window.stream = stream;
        audio.srcObject = stream; // this should take from the decoded recieved data 

        let audioEncoder = await buildAndConfigureEncoders();

        if (audioEncoder == null){
          console.log("Encoder Failed to buildAndConfigure, returned null")
          return;  // More elaborate fallback recommended.
        }
        const readableAudio = (new MediaStreamTrackProcessor(audioTrack)).readable;

        // Feed the encoders data from the track readers. Encoded outputs are
        // immediately sent on the wire. See readAndEncode() definition from
        // earlier examples.
        readAndEncode(readableAudio.getReader(), audioEncoder);

        // Setup decoders and check for unsupported configuration.
        let audioDecoder = await buildAndConfigureDecoders();
        if (audioDecoder == null)
          return;  // More elaborate fallback recommended.

        // Start streaming encoded data, repeatedly calling decode callbacks for each chunk.
        streamEncodedChunks(audioDecoder.decode.bind(audioDecoder));

      }

      function handleError(error) {
        const errorMessage = 'navigator.MediaDevices.getUserMedia error: ' + error.message + ' ' + error.name;
        document.getElementById('errorMsg').innerText = errorMessage;
        console.log(errorMessage);
      }

      function sendAudio(encodedAudio) {
        console.log('sending encoded Audio: ' + encodedAudio);
      }

      function streamEncodedChunks(decodeAudioCallback) {
        console.log('decoding and streaming decoded Audio : ' + decodeAudioCallback);
      }

      function renderInAudioWorklet(audioFrame) { 
        console.log('rendering in AudioWorklet: ' + audioFrame);
      }

      function onCodecError(error){
        console.log(`Error = ${error}`);
      }

      function readAndEncode(reader, encoder) {
        // TODO: maybe not so cache-friendly 
        reader.read().then((result) => {
          // App handling for stream closure.
          if (result.done)
            return;

          encoder.encode(result.value);

          readAndEncode(reader, encoder);
        });
      }

      async function buildAndConfigureEncoders() {
          // Encoded outputs immmediately sent on the wire.
        let audioEncoder = new AudioEncoder({ output: sendAudio, error: onCodecError });
        try {
          await audioEncoder.configure({ codec: 'opus', numberOfChannels: 1,sampleRate: 48000});
        } catch (exception) {
          console.log("Exception when configuring audioEncoder: " + exception);
          audioEncoder = null;
        }
        return audioEncoder;
      }

      async function buildAndConfigureDecoders(audioEncoder) {
        let audioDecoder = new AudioDecoder({ output: renderInAudioWorklet, error: onCodecError });
        try {
          await audioDecoder.configure({ codec: 'opus', numberOfChannels: 1,sampleRate: 48000});
        } catch (exception) {
          console.log(" Exception when configuring audioDecoder: " + exception)
          audioDecoder = null;
        }
        return audioDecoder;
      }

                
      navigator.mediaDevices.getUserMedia(constraints).then(handleSuccess).catch(handleError);

    })

  </script>

<% end %>

<% content_for(:body) do %>
  <div id="container">

      <h1><a href="//webrtc.github.io/samples/" title="WebRTC samples homepage">WebRTC samples</a> <span>getUserMedia, audio only</span>
      </h1>

      <audio id="gum-local" controls></audio>

      <p class="warning">Warning: if you're not using headphones, pressing play will cause feedback.</p>

      <p>Render the audio stream from an audio-only <code>getUserMedia()</code> call with an audio element.</p>

      <p>The <code>MediaStream</code> object <code><em>stream</em></code> passed to the <code>getUserMedia()</code>
          callback is in global scope, so you can inspect it from the console.</p>
      <div>
          <span id="errorMsg"></span>
      </div>
      
      <a href="https://github.com/webrtc/samples/tree/gh-pages/src/content/getusermedia/audio"
        title="View source for this page on GitHub" id="viewSource">View source on GitHub</a>

  </div>


<% end %>